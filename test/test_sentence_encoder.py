#!/usr/bin/env python3
"""
sentence_encoder.py æµ‹è¯•æ¨¡å—

æµ‹è¯•å¥å­ç¼–ç å™¨çš„å„ç§åŠŸèƒ½ï¼ŒåŒ…æ‹¬å•æ–‡æœ¬ç¼–ç ã€æ‰¹é‡ç¼–ç ã€ç›¸ä¼¼åº¦è®¡ç®—ç­‰ã€‚
"""

import asyncio
import sys
import os
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from page.sentence_encoder import SentenceEncoder, encode, similarity


async def test_different_length_texts():
    """æµ‹è¯•ä¸åŒé•¿åº¦æ–‡æœ¬ç¼–ç """
    print("\nğŸ” æµ‹è¯•ä¸åŒé•¿åº¦æ–‡æœ¬ç¼–ç :")
    
    encoder = SentenceEncoder()
    await encoder.load_model()
    
    test_cases = [
        ("çŸ­æ–‡æœ¬", "Hello"),
        ("ä¸­ç­‰æ–‡æœ¬", "è¿™æ˜¯ä¸€ä¸ªä¸­ç­‰é•¿åº¦çš„æµ‹è¯•æ–‡æœ¬ï¼ŒåŒ…å«ä¸€äº›ä¸­æ–‡å’Œè‹±æ–‡å†…å®¹ã€‚"),
        ("é•¿æ–‡æœ¬", "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æµ‹è¯•æ–‡æœ¬ã€‚" * 100),  # çº¦500è¯
        ("è¶…é•¿æ–‡æœ¬", "è¿™æ˜¯ä¸€ä¸ªè¶…é•¿çš„æµ‹è¯•æ–‡æœ¬ã€‚" * 200),  # çº¦1000è¯
    ]
    
    for desc, text in test_cases:
        try:
            start_time = time.time()
            embedding = await encoder.encode(text)
            duration = time.time() - start_time
            word_count = len(text.split())
            print(f"   âœ… {desc}: {word_count}è¯, {embedding.shape[0]}ç»´, {duration:.3f}ç§’")
        except Exception as e:
            print(f"   âŒ {desc}: å¤±è´¥ - {e}")


async def test_multilingual_similarity():
    """æµ‹è¯•å¤šè¯­è¨€ç›¸ä¼¼åº¦è®¡ç®—"""
    print("\nğŸŒ æµ‹è¯•å¤šè¯­è¨€ç›¸ä¼¼åº¦è®¡ç®—:")
    
    encoder = SentenceEncoder()
    await encoder.load_model()
    
    test_pairs = [
        ("ä»Šå¤©å¤©æ°”å¾ˆå¥½", "ä»Šå¤©å¤©æ°”ä¸é”™", "ä¸­æ–‡ç›¸ä¼¼"),
        ("Hello world", "Hi there", "è‹±æ–‡ç›¸ä¼¼"),
        ("ä»Šå¤©å¤©æ°”å¾ˆå¥½", "Hello world", "ä¸­è‹±æ··åˆ"),
        ("ä»Šå¤©å¤©æ°”å¾ˆå¥½", "æ˜å¤©è¦ä¸‹é›¨", "ä¸­æ–‡ä¸ç›¸ä¼¼"),
        ("The weather is nice today", "Il fait beau aujourd'hui", "è‹±æ³•æ··åˆ"),
    ]
    
    for text1, text2, desc in test_pairs:
        try:
            similarity_score = await encoder.similarity(text1, text2)
            print(f"   âœ… {desc}: {similarity_score:.4f}")
        except Exception as e:
            print(f"   âŒ {desc}: å¤±è´¥ - {e}")


async def test_batch_encoding_performance():
    """æµ‹è¯•æ‰¹é‡ç¼–ç æ€§èƒ½"""
    print("\nâš¡ æµ‹è¯•æ‰¹é‡ç¼–ç æ€§èƒ½:")
    
    encoder = SentenceEncoder()
    await encoder.load_model()
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    test_texts = [f"è¿™æ˜¯ç¬¬{i}ä¸ªæµ‹è¯•æ–‡æœ¬ï¼ŒåŒ…å«ä¸€äº›ä¸­æ–‡å†…å®¹ã€‚" for i in range(100)]
    
    try:
        start_time = time.time()
        embeddings = await encoder.encode_batch(test_texts, show_progress=True)
        duration = time.time() - start_time
        
        print(f"   âœ… æ‰¹é‡ç¼–ç : {len(test_texts)}ä¸ªæ–‡æœ¬, {embeddings.shape}, {duration:.3f}ç§’")
        print(f"   ğŸ“Š å¹³å‡é€Ÿåº¦: {len(test_texts)/duration:.1f} æ–‡æœ¬/ç§’")
        
        # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        stats = encoder.get_stats()
        print(f"   ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡: {stats}")
        
    except Exception as e:
        print(f"   âŒ æ‰¹é‡ç¼–ç å¤±è´¥: {e}")


async def test_singleton_pattern():
    """æµ‹è¯•å•ä¾‹æ¨¡å¼"""
    print("\nğŸ”§ æµ‹è¯•å•ä¾‹æ¨¡å¼:")
    
    encoder1 = SentenceEncoder()
    encoder2 = SentenceEncoder()
    
    print(f"   âœ… å•ä¾‹æ¨¡å¼: {encoder1 is encoder2}")
    print(f"   âœ… æ¨¡å‹å®ä¾‹: {encoder1.model is encoder2.model}")


async def test_convenience_functions():
    """æµ‹è¯•ä¾¿æ·å‡½æ•°"""
    print("\nğŸš€ æµ‹è¯•ä¾¿æ·å‡½æ•°:")
    
    try:
        # æµ‹è¯•ä¾¿æ·ç¼–ç å‡½æ•°
        embedding = await encode("æµ‹è¯•æ–‡æœ¬")
        print(f"   âœ… ä¾¿æ·ç¼–ç å‡½æ•°: {embedding.shape}")
        
        # æµ‹è¯•ä¾¿æ·ç›¸ä¼¼åº¦å‡½æ•°
        sim = await similarity("ä»Šå¤©å¤©æ°”å¾ˆå¥½", "ä»Šå¤©å¤©æ°”ä¸é”™")
        print(f"   âœ… ä¾¿æ·ç›¸ä¼¼åº¦å‡½æ•°: {sim:.4f}")
        
    except Exception as e:
        print(f"   âŒ ä¾¿æ·å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")


async def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\nğŸ›¡ï¸ æµ‹è¯•é”™è¯¯å¤„ç†:")
    
    encoder = SentenceEncoder()
    
    try:
        # æµ‹è¯•ç©ºæ–‡æœ¬
        empty_embedding = await encoder.encode("")
        print(f"   âœ… ç©ºæ–‡æœ¬å¤„ç†: {empty_embedding.shape}")
        
        # æµ‹è¯•ç©ºæ–‡æœ¬åˆ—è¡¨
        empty_batch = await encoder.encode_batch([])
        print(f"   âœ… ç©ºæ–‡æœ¬åˆ—è¡¨å¤„ç†: {empty_batch.shape}")
        
        # æµ‹è¯•ç©ºæ–‡æœ¬ç›¸ä¼¼åº¦
        empty_sim = await encoder.similarity("", "")
        print(f"   âœ… ç©ºæ–‡æœ¬ç›¸ä¼¼åº¦: {empty_sim}")
        
    except Exception as e:
        print(f"   âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥: {e}")


async def test_environment_variables():
    """æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®"""
    print("\nâš™ï¸ æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®:")
    
    # æµ‹è¯•é»˜è®¤é…ç½®
    encoder = SentenceEncoder()
    print(f"   âœ… é»˜è®¤æ¨¡å‹: {encoder.model_name}")
    print(f"   âœ… é»˜è®¤è®¾å¤‡: {encoder.device}")
    print(f"   âœ… ç¦»çº¿æ¨¡å¼: {encoder.offline_mode}")


async def test_performance_monitoring():
    """æµ‹è¯•æ€§èƒ½ç›‘æ§"""
    print("\nğŸ“Š æµ‹è¯•æ€§èƒ½ç›‘æ§:")
    
    encoder = SentenceEncoder()
    await encoder.load_model()
    
    # é‡ç½®ç»Ÿè®¡
    encoder.reset_stats()
    
    # æ‰§è¡Œä¸€äº›æ“ä½œ
    await encoder.encode("æµ‹è¯•æ–‡æœ¬1")
    await encoder.encode("æµ‹è¯•æ–‡æœ¬2")
    await encoder.similarity("æ–‡æœ¬1", "æ–‡æœ¬2")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = encoder.get_stats()
    print(f"   âœ… æ€»ç¼–ç æ¬¡æ•°: {stats['total_encodings']}")
    print(f"   âœ… æ€»ç›¸ä¼¼åº¦è®¡ç®—: {stats['total_similarities']}")
    print(f"   âœ… å¹³å‡ç¼–ç æ—¶é—´: {stats['avg_encoding_time']:.3f}ç§’")
    print(f"   âœ… å¤„ç†é€Ÿåº¦: {stats['throughput']:.1f} æ–‡æœ¬/ç§’")
    print(f"   âœ… å³°å€¼å†…å­˜: {stats['peak_memory']:.1f}MB")


async def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•SentenceEncoder v2.0åŠŸèƒ½")
    print("=" * 60)
    
    try:
        # æµ‹è¯•å•ä¾‹æ¨¡å¼
        await test_singleton_pattern()
        
        # æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®
        await test_environment_variables()
        
        # æµ‹è¯•ä¾¿æ·å‡½æ•°
        await test_convenience_functions()
        
        # æµ‹è¯•é”™è¯¯å¤„ç†
        await test_error_handling()
        
        # æµ‹è¯•ä¸åŒé•¿åº¦æ–‡æœ¬ç¼–ç 
        await test_different_length_texts()
        
        # æµ‹è¯•å¤šè¯­è¨€ç›¸ä¼¼åº¦è®¡ç®—
        await test_multilingual_similarity()
        
        # æµ‹è¯•æ‰¹é‡ç¼–ç æ€§èƒ½
        await test_batch_encoding_performance()
        
        # æµ‹è¯•æ€§èƒ½ç›‘æ§
        await test_performance_monitoring()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ SentenceEncoder v2.0åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
